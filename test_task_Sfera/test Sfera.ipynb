{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baa6b108",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка-и-обзор-данных\" data-toc-modified-id=\"Подготовка-и-обзор-данных-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка и обзор данных</a></span></li><li><span><a href=\"#Обучение-модели\" data-toc-modified-id=\"Обучение-модели-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение модели</a></span><ul class=\"toc-item\"><li><span><a href=\"#LogisticRegression\" data-toc-modified-id=\"LogisticRegression-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>LogisticRegression</a></span></li><li><span><a href=\"#RandomForest\" data-toc-modified-id=\"RandomForest-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>RandomForest</a></span></li><li><span><a href=\"#DecisionTree\" data-toc-modified-id=\"DecisionTree-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>DecisionTree</a></span></li><li><span><a href=\"#XGBoost\" data-toc-modified-id=\"XGBoost-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>XGBoost</a></span></li></ul></li><li><span><a href=\"#Bert\" data-toc-modified-id=\"Bert-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Bert</a></span></li><li><span><a href=\"#Вывод\" data-toc-modified-id=\"Вывод-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Вывод</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3afdae",
   "metadata": {},
   "source": [
    "Перед нами стоит задача классификации. Необходимо обучить модель, которая по тексту в вакансии будет определять формат работы - удаленный, или нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9cc2f8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from pymystem3 import Mystem\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from tqdm import notebook \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import functools\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel, BertModel, BertConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc75ecf",
   "metadata": {},
   "source": [
    "## Подготовка и обзор данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a08772a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Найдено в</th>\n",
       "      <th>Текст</th>\n",
       "      <th>Удаленка</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67259437</td>\n",
       "      <td>Описание</td>\n",
       "      <td>Желание работать на всесезонной базе отдыха кл...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67542900</td>\n",
       "      <td>Описание</td>\n",
       "      <td>График работы: 5/2, возможна удаленная работа ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>66953697</td>\n",
       "      <td>Описание</td>\n",
       "      <td>6.Ежедневная проверка классных и домашних рабо...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67381114</td>\n",
       "      <td>Описание</td>\n",
       "      <td>Работа РЯДОМ С ДОМОМ</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67624820</td>\n",
       "      <td>Описание</td>\n",
       "      <td>Удаленная работа</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID Найдено в                                              Текст  \\\n",
       "0  67259437  Описание  Желание работать на всесезонной базе отдыха кл...   \n",
       "1  67542900  Описание  График работы: 5/2, возможна удаленная работа ...   \n",
       "2  66953697  Описание  6.Ежедневная проверка классных и домашних рабо...   \n",
       "3  67381114  Описание                               Работа РЯДОМ С ДОМОМ   \n",
       "4  67624820  Описание                                   Удаленная работа   \n",
       "\n",
       "   Удаленка  \n",
       "0         0  \n",
       "1         1  \n",
       "2         0  \n",
       "3        -1  \n",
       "4         1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('C:/Users/User/Desktop/123/test.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab3b69a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1368 entries, 0 to 1367\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   ID         1368 non-null   int64 \n",
      " 1   Найдено в  1368 non-null   object\n",
      " 2   Текст      1368 non-null   object\n",
      " 3   Удаленка   1368 non-null   int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 42.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ee0070f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAASqklEQVR4nO3df4xd5X3n8fdn7UIbnIApzdTFbPFK3rTQH9swYtNk1R2Lqjj0h9k/kBylrdlFsroiLV21q5qutKlUWUtWaqV2Uyp5Q4S7RBl5CVusENpSl2nUH8BimsQYl+KUlBhce5sAzUQVDex3/7iHzZU945lz79xryPN+SaN77nOe55zvPPfwucdn7j2kqpAkteGfnO8CJEnTY+hLUkMMfUlqiKEvSQ0x9CWpIevPdwErueyyy+rKK68caexXv/pVLrroorUtaA1YVz/W1Y919fONWtfhw4f/rqq+7awVVfWG/rnmmmtqVA8//PDIYyfJuvqxrn6sq59v1LqAx2uJTPXyjiQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWrIiqGf5KNJTid5cqjt0iQPJXmme9w4tO72JMeTPJ3k+qH2a5Ic6db9ZpKs/a8jSTqX1Zzp3w1sP6NtD3CoqrYCh7rnJLkK2Alc3Y25M8m6bsxvA7uBrd3PmduUJE3YiqFfVZ8GvnxG8w5gf7e8H7hxqH2+ql6pqmeB48C1STYBb6uqP+++NPA7Q2MkSVMy6m0YZqrqJEBVnUzy9q79cuCRoX4nuravdctntkvSG9qVex44L/u9e/tkbg2x1vfeWeo6fZ2jfemNJLsZXApiZmaGhYWFkYpZXFwceewkWVc/1tWPdfWzUl2/8L2vTq+YIZOar1FD/1SSTd1Z/ibgdNd+ArhiqN9m4IWuffMS7Uuqqn3APoDZ2dmam5sbqciFhQVGHTtJ1tWPdfVjXf2sVNfN5/FMfxLzNepHNg8Cu7rlXcD9Q+07k1yYZAuDP9g+1l0K+kqSd3Wf2vnpoTGSpClZ8Uw/yceBOeCyJCeADwJ3AAeS3AI8B9wEUFVHkxwAngJeBW6tqte6Tf17Bp8E+hbgwe5HkjRFK4Z+Vb1vmVXXLdN/L7B3ifbHge/pVZ0kaU35jVxJaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWrIWKGf5D8kOZrkySQfT/LNSS5N8lCSZ7rHjUP9b09yPMnTSa4fv3xJUh8jh36Sy4GfA2ar6nuAdcBOYA9wqKq2Aoe65yS5qlt/NbAduDPJuvHKlyT1Me7lnfXAtyRZD7wFeAHYAezv1u8HbuyWdwDzVfVKVT0LHAeuHXP/kqQeUlWjD05uA/YC/wD8QVW9P8lLVXXJUJ8Xq2pjkg8Dj1TVPV37XcCDVXXvEtvdDewGmJmZuWZ+fn6k+hYXF9mwYcNIYyfJuvqxrn6sq5+V6jry/MtTrObrtly8bqz52rZt2+Gqmj2zff2oG+yu1e8AtgAvAf8zyU+ea8gSbUu+41TVPmAfwOzsbM3NzY1U48LCAqOOnSTr6se6+rGuflaq6+Y9D0yvmCF3b79oIvM1zuWdHwaerar/U1VfA+4D3g2cSrIJoHs83fU/AVwxNH4zg8tBkqQpGSf0nwPeleQtSQJcBxwDDgK7uj67gPu75YPAziQXJtkCbAUeG2P/kqSeRr68U1WPJrkXeAJ4FfgLBpdkNgAHktzC4I3hpq7/0SQHgKe6/rdW1Wtj1i9J6mHk0Aeoqg8CHzyj+RUGZ/1L9d/L4A+/kqTzwG/kSlJDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhoyVugnuSTJvUn+MsmxJD+Y5NIkDyV5pnvcONT/9iTHkzyd5Prxy5ck9THumf5vAL9XVd8FfD9wDNgDHKqqrcCh7jlJrgJ2AlcD24E7k6wbc/+SpB5GDv0kbwN+CLgLoKr+sapeAnYA+7tu+4Ebu+UdwHxVvVJVzwLHgWtH3b8kqb9U1WgDk38B7AOeYnCWfxi4DXi+qi4Z6vdiVW1M8mHgkaq6p2u/C3iwqu5dYtu7gd0AMzMz18zPz49U4+LiIhs2bBhp7CRZVz/W1Y919bNSXUeef3mK1XzdlovXjTVf27ZtO1xVs2e2rx+jpvXAO4GfrapHk/wG3aWcZWSJtiXfcapqH4M3FGZnZ2tubm6kAhcWFhh17CRZVz/W1Y919bNSXTfveWB6xQy5e/tFE5mvca7pnwBOVNWj3fN7GbwJnEqyCaB7PD3U/4qh8ZuBF8bYvySpp5FDv6r+Fvhiknd0TdcxuNRzENjVte0C7u+WDwI7k1yYZAuwFXhs1P1Lkvob5/IOwM8CH0tyAfDXwL9l8EZyIMktwHPATQBVdTTJAQZvDK8Ct1bVa2PuX5LUw1ihX1WfAc76QwGDs/6l+u8F9o6zT0nS6PxGriQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0JakhY4d+knVJ/iLJJ7vnlyZ5KMkz3ePGob63Jzme5Okk14+7b0lSP2txpn8bcGzo+R7gUFVtBQ51z0lyFbATuBrYDtyZZN0a7F+StEpjhX6SzcCPAh8Zat4B7O+W9wM3DrXPV9UrVfUscBy4dpz9S5L6SVWNPji5F/gvwFuBX6yqH0vyUlVdMtTnxaramOTDwCNVdU/XfhfwYFXdu8R2dwO7AWZmZq6Zn58fqb7FxUU2bNgw0thJsq5+rKsf6+pnpbqOPP/yFKv5ui0XrxtrvrZt23a4qmbPbF8/6gaT/BhwuqoOJ5lbzZAl2pZ8x6mqfcA+gNnZ2ZqbW83mz7awsMCoYyfJuvqxrn6sq5+V6rp5zwPTK2bI3dsvmsh8jRz6wHuAn0hyA/DNwNuS3AOcSrKpqk4m2QSc7vqfAK4YGr8ZeGGM/UuSehr5mn5V3V5Vm6vqSgZ/oP2jqvpJ4CCwq+u2C7i/Wz4I7ExyYZItwFbgsZErlyT1Ns6Z/nLuAA4kuQV4DrgJoKqOJjkAPAW8CtxaVa9NYP+SpGWsSehX1QKw0C1/CbhumX57gb1rsU9JUn9+I1eSGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUkJFDP8kVSR5OcizJ0SS3de2XJnkoyTPd48ahMbcnOZ7k6STXr8UvIElavfVjjH0V+IWqeiLJW4HDSR4CbgYOVdUdSfYAe4BfSnIVsBO4GvgO4A+T/POqem28X2F5R55/mZv3PDCpzS/rC3f86NT3KUmrMfKZflWdrKonuuWvAMeAy4EdwP6u237gxm55BzBfVa9U1bPAceDaUfcvSepvTa7pJ7kS+AHgUWCmqk7C4I0BeHvX7XLgi0PDTnRtkqQpSVWNt4FkA/DHwN6qui/JS1V1ydD6F6tqY5LfAv68qu7p2u8CPlVVn1him7uB3QAzMzPXzM/Pj1Tb6S+/zKl/GGnoWL738ovPuX5xcZENGzZMqZrVs65+rKufN2tdR55/eYrVfN2Wi9eNNV/btm07XFWzZ7aPc02fJN8EfAL4WFXd1zWfSrKpqk4m2QSc7tpPAFcMDd8MvLDUdqtqH7APYHZ2tubm5kaq77997H5+7chYv+JIvvD+uXOuX1hYYNTfaZKsqx/r6ufNWtf5+LsgwN3bL5rIfI3z6Z0AdwHHqurXh1YdBHZ1y7uA+4fadya5MMkWYCvw2Kj7lyT1N85p8HuAnwKOJPlM1/bLwB3AgSS3AM8BNwFU1dEkB4CnGHzy59ZJfnJHknS2kUO/qv4EyDKrr1tmzF5g76j7lCSNx2/kSlJDDH1JaoihL0kNMfQlqSHT/xC79A3ifN3bCby/k0bnmb4kNcTQl6SGGPqS1BBDX5IaYuhLUkMMfUlqiKEvSQ0x9CWpIYa+JDXE0Jekhhj6ktQQQ1+SGmLoS1JDDH1JaoihL0kNMfQlqSGGviQ1xNCXpIYY+pLUEENfkhpi6EtSQwx9SWqIoS9JDTH0Jakhhr4kNcTQl6SGGPqS1BBDX5IaMvXQT7I9ydNJjifZM+39S1LLphr6SdYBvwW8F7gKeF+Sq6ZZgyS1bNpn+tcCx6vqr6vqH4F5YMeUa5CkZq2f8v4uB7449PwE8C/P7JRkN7C7e7qY5OkR93cZ8Hcjjh1ZPrRil/NS1ypYVz/nra4VjjHnq583ZF3bPjR2Xd+5VOO0Qz9LtNVZDVX7gH1j7yx5vKpmx93OWrOufqyrH+vqp7W6pn155wRwxdDzzcALU65Bkpo17dD/38DWJFuSXADsBA5OuQZJatZUL+9U1atJPgD8PrAO+GhVHZ3gLse+RDQh1tWPdfVjXf00VVeqzrqkLkn6BuU3ciWpIYa+JDXkTR/6SW5KcjTJ/02y7Meblrv9Q5JLkzyU5JnuceMa1bXidpO8I8lnhn7+PsnPd+t+JcnzQ+tumFZdXb8vJDnS7fvxvuMnUVeSK5I8nORY95rfNrRuTedrpduFZOA3u/WfS/LO1Y6dcF3v7+r5XJI/S/L9Q+uWfE2nVNdckpeHXp//vNqxE67rPw7V9GSS15Jc2q2byHwl+WiS00meXGb9ZI+tqnpT/wDfDbwDWABml+mzDvg88M+AC4DPAld16/4rsKdb3gN8aI3q6rXdrsa/Bb6ze/4rwC9OYL5WVRfwBeCycX+vtawL2AS8s1t+K/BXQ6/jms3XuY6XoT43AA8y+O7Ju4BHVzt2wnW9G9jYLb/39brO9ZpOqa454JOjjJ1kXWf0/3Hgj6YwXz8EvBN4cpn1Ez223vRn+lV1rKpW+sbuuW7/sAPY3y3vB25co9L6bvc64PNV9TdrtP/ljPv7nrf5qqqTVfVEt/wV4BiDb3mvtdXcLmQH8Ds18AhwSZJNqxw7sbqq6s+q6sXu6SMMvgszaeP8zud1vs7wPuDja7TvZVXVp4Evn6PLRI+tN33or9JSt394PSxmquokDEIFePsa7bPvdndy9gH3ge6fdx9dq8soPeoq4A+SHM7gthh9x0+qLgCSXAn8APDoUPNazde5jpeV+qxm7CTrGnYLgzPG1y33mk6rrh9M8tkkDya5uufYSdZFkrcA24FPDDVPar5WMtFja9q3YRhJkj8Evn2JVf+pqu5fzSaWaBv7s6rnqqvndi4AfgK4faj5t4FfZVDnrwK/Bvy7Kdb1nqp6IcnbgYeS/GV3hjKyNZyvDQz+4/z5qvr7rnnk+VpqF0u0nXm8LNdnIsfaCvs8u2OyjUHo/6uh5jV/TXvU9QSDS5eL3d9bfhfYusqxk6zrdT8O/GlVDZ+BT2q+VjLRY+tNEfpV9cNjbuJct384lWRTVZ3s/gl1ei3qStJnu+8FnqiqU0Pb/v/LSf478Mlp1lVVL3SPp5P8Lwb/tPw053m+knwTg8D/WFXdN7TtkedrCau5XchyfS5YxdhJ1kWS7wM+Ary3qr70evs5XtOJ1zX05kxVfSrJnUkuW83YSdY15Kx/aU9wvlYy0WOrlcs757r9w0FgV7e8C1jNvxxWo892z7qW2AXf6/4NsORf+idRV5KLkrz19WXgR4b2f97mK0mAu4BjVfXrZ6xby/laze1CDgI/3X3S4l3Ay91lqUneamTFbSf5p8B9wE9V1V8NtZ/rNZ1GXd/evX4kuZZB9nxpNWMnWVdXz8XAv2bomJvwfK1kssfWWv9leto/DP4DPwG8ApwCfr9r/w7gU0P9bmDwaY/PM7gs9Hr7twKHgGe6x0vXqK4lt7tEXW9hcPBffMb4/wEcAT7XvbCbplUXg08HfLb7OfpGmS8Glyqqm5PPdD83TGK+ljpegJ8BfqZbDoP/IdDnu/3OnmvsGh7vK9X1EeDFofl5fKXXdEp1faDb72cZ/IH53W+E+eqe3wzMnzFuYvPF4ATvJPA1Btl1yzSPLW/DIEkNaeXyjiQJQ1+SmmLoS1JDDH1JaoihL0kNMfQlqSGGviQ15P8BeNWf8mlafmIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['Удаленка'].hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a5dbe77",
   "metadata": {},
   "source": [
    "Есть дисбаланс классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdfc2fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047418d3",
   "metadata": {},
   "source": [
    "Датафрейм содержит три столбца:\n",
    "- ID - id вакансии в базе\n",
    "- Найдено в - столбец, который отображает где найдена информация об удаленной работе, в описании или названии вакансии\n",
    "- Текст - информация в вакансии. Текс, с котором нам предстоит работать\n",
    "- Удаленка - разметка данных, которая отображает удаленная работа описана в вакансии или нет.\n",
    "\n",
    "В данных нет пропусков, и нет дубликатов. В таблице 1368 записей. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb2cefb",
   "metadata": {},
   "source": [
    "Переименуем столбцы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07a30936",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns=['id', 'found_in', 'text', 'remote']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc553f03",
   "metadata": {},
   "source": [
    "Для дальнейшей работы нам необходимы только два столбца text и remote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86ed3bba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>remote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Желание работать на всесезонной базе отдыха кл...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>График работы: 5/2, возможна удаленная работа ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.Ежедневная проверка классных и домашних рабо...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Работа РЯДОМ С ДОМОМ</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Удаленная работа</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  remote\n",
       "0  Желание работать на всесезонной базе отдыха кл...       0\n",
       "1  График работы: 5/2, возможна удаленная работа ...       1\n",
       "2  6.Ежедневная проверка классных и домашних рабо...       0\n",
       "3                               Работа РЯДОМ С ДОМОМ      -1\n",
       "4                                   Удаленная работа       1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[['text', 'remote']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea03fc7",
   "metadata": {},
   "source": [
    "Текст, с которым будем работать, на русском языке. Поэтому для его лемматизации будем использовать библиотеку pymystem3. Лемматизируем наш текс, и сразу удалим из него лишние символы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "513b9272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c715799223624443ad6f67c0fd9e3aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1368 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "m = Mystem()\n",
    "for i in notebook.tqdm(range(len(data['text']))):\n",
    "    lemm_list = m.lemmatize(data['text'][i])\n",
    "    data['text'][i] = \" \".join(lemm_list)\n",
    "    a = re.sub(r'[^а-яА-ЯёЁ ]', ' ', data['text'][i])\n",
    "    data['text'][i] = ' '.join(a.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00b4917f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>remote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>желание работать на всесезонный база отдых клу...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>график работа возможный удаленный работа техни...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ежедневный проверка классный и домашний работа...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>работа рядом с дом</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>удаленный работа</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  remote\n",
       "0  желание работать на всесезонный база отдых клу...       0\n",
       "1  график работа возможный удаленный работа техни...       1\n",
       "2  ежедневный проверка классный и домашний работа...       0\n",
       "3                                 работа рядом с дом      -1\n",
       "4                                   удаленный работа       1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28757c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data['text']\n",
    "target = data['remote']\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.2, random_state=148)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb415430",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('russian'))\n",
    "count_tf_idf = TfidfVectorizer(stop_words=stopwords)\n",
    "features_train = count_tf_idf.fit_transform(features_train)\n",
    "features_test = count_tf_idf.transform(features_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071a93e0",
   "metadata": {},
   "source": [
    "## Обучение модели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e13002",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10961e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "F1: 0.8679400721498837\n",
      "Accuracy: 0.8795620437956204\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "model_l_r = LogisticRegression(solver=\"saga\", max_iter=1000)\n",
    "model_l_r.fit(features_train, target_train)\n",
    "p = model_l_r.predict(features_test)\n",
    "print('F1:', f1_score(target_test, p, average='weighted'))\n",
    "print('Accuracy:', accuracy_score(target_test, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775e9a00",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d68b6319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "F1: 0.8828411641194595\n",
      "Accuracy: 0.8905109489051095\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "model_f = RandomForestClassifier(class_weight='balanced')\n",
    "model_f.fit(features_train, target_train)\n",
    "p = model_f.predict(features_test)\n",
    "print('F1:', f1_score(target_test, p, average='weighted'))\n",
    "print('Accuracy:', accuracy_score(target_test, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3e81b8",
   "metadata": {},
   "source": [
    "### DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4af37636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "F1: 0.8640796268206662\n",
      "Accuracy: 0.864963503649635\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "model_t = DecisionTreeClassifier(class_weight='balanced')\n",
    "model_t.fit(features_train, target_train)\n",
    "p = model_t.predict(features_test)\n",
    "print('F1:', f1_score(target_test, p, average='weighted'))\n",
    "print('Accuracy:', accuracy_score(target_test, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70aa9be0",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "894decb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def opt(X_train, y_train, X_test, y_test, trial):\n",
    "    #param_list\n",
    "    n_estimators = trial.suggest_int('n_estimators', 0, 1000)\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 20)\n",
    "    min_child_weight = trial.suggest_int('min_child_weight', 1, 20)\n",
    "    #learning_rate = trial.suggest_discrete_uniform('learning_rate', 0.01, 0.1, 0.01)\n",
    "    #scale_pos_weight = trial.suggest_int('scale_pos_weight', 1, 100)\n",
    "    subsample = trial.suggest_discrete_uniform('subsample', 0.5, 0.9, 0.1)\n",
    "    colsample_bytree = trial.suggest_discrete_uniform('colsample_bytree', 0.5, 0.9, 0.1)\n",
    "\n",
    "    xgboost_tuna = xgb.XGBClassifier(\n",
    "        random_state=148,\n",
    "        n_estimators = n_estimators,\n",
    "        max_depth = max_depth,\n",
    "        min_child_weight = min_child_weight,\n",
    "        #learning_rate = learning_rate,\n",
    "        #scale_pos_weight = scale_pos_weight,\n",
    "        subsample = subsample,\n",
    "        colsample_bytree = colsample_bytree,\n",
    "    )\n",
    "    xgboost_tuna.fit(X_train, y_train)\n",
    "    tuna_pred_test = xgboost_tuna.predict(X_test)\n",
    "    \n",
    "    return (accuracy_score(y_test, tuna_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d4d0484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:55:17,245]\u001b[0m A new study created in memory with name: no-name-b33ea51d-03f8-4c2a-a691-9be3e1938075\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:55:17] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2022-07-30 19:55:19,492]\u001b[0m Trial 0 finished with value: 0.8394160583941606 and parameters: {'n_estimators': 975, 'max_depth': 14, 'min_child_weight': 12, 'subsample': 0.5, 'colsample_bytree': 0.9}. Best is trial 0 with value: 0.8394160583941606.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:55:19] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:55:19,873]\u001b[0m Trial 1 finished with value: 0.8686131386861314 and parameters: {'n_estimators': 218, 'max_depth': 1, 'min_child_weight': 18, 'subsample': 0.8, 'colsample_bytree': 0.5}. Best is trial 0 with value: 0.8394160583941606.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:55:19] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:55:20,324]\u001b[0m Trial 2 finished with value: 0.8868613138686131 and parameters: {'n_estimators': 119, 'max_depth': 5, 'min_child_weight': 4, 'subsample': 0.9, 'colsample_bytree': 0.8}. Best is trial 0 with value: 0.8394160583941606.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:55:20] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:55:21,127]\u001b[0m Trial 3 finished with value: 0.8613138686131386 and parameters: {'n_estimators': 397, 'max_depth': 6, 'min_child_weight': 20, 'subsample': 0.6, 'colsample_bytree': 0.6}. Best is trial 0 with value: 0.8394160583941606.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:55:21] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:55:21,950]\u001b[0m Trial 4 finished with value: 0.8759124087591241 and parameters: {'n_estimators': 145, 'max_depth': 18, 'min_child_weight': 2, 'subsample': 0.9, 'colsample_bytree': 0.9}. Best is trial 0 with value: 0.8394160583941606.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:55:21] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:55:23,486]\u001b[0m Trial 5 finished with value: 0.8759124087591241 and parameters: {'n_estimators': 409, 'max_depth': 12, 'min_child_weight': 2, 'subsample': 0.9, 'colsample_bytree': 0.7}. Best is trial 0 with value: 0.8394160583941606.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:55:23] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:55:24,061]\u001b[0m Trial 6 finished with value: 0.8686131386861314 and parameters: {'n_estimators': 340, 'max_depth': 1, 'min_child_weight': 11, 'subsample': 0.5, 'colsample_bytree': 0.7}. Best is trial 0 with value: 0.8394160583941606.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:55:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:55:25,131]\u001b[0m Trial 7 finished with value: 0.864963503649635 and parameters: {'n_estimators': 489, 'max_depth': 16, 'min_child_weight': 16, 'subsample': 0.8, 'colsample_bytree': 0.5}. Best is trial 0 with value: 0.8394160583941606.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:55:25] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:55:27,228]\u001b[0m Trial 8 finished with value: 0.8832116788321168 and parameters: {'n_estimators': 844, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.5, 'colsample_bytree': 0.5}. Best is trial 0 with value: 0.8394160583941606.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:55:27] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:55:27,494]\u001b[0m Trial 9 finished with value: 0.8759124087591241 and parameters: {'n_estimators': 81, 'max_depth': 11, 'min_child_weight': 18, 'subsample': 0.8, 'colsample_bytree': 0.8}. Best is trial 0 with value: 0.8394160583941606.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:55:27] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:55:29,871]\u001b[0m Trial 10 finished with value: 0.8284671532846716 and parameters: {'n_estimators': 958, 'max_depth': 14, 'min_child_weight': 10, 'subsample': 0.6, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:55:29] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:55:32,348]\u001b[0m Trial 11 finished with value: 0.8321167883211679 and parameters: {'n_estimators': 989, 'max_depth': 15, 'min_child_weight': 10, 'subsample': 0.6, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:55:32] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:55:34,328]\u001b[0m Trial 12 finished with value: 0.8613138686131386 and parameters: {'n_estimators': 736, 'max_depth': 20, 'min_child_weight': 8, 'subsample': 0.6, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:55:34] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:55:36,123]\u001b[0m Trial 13 finished with value: 0.8540145985401459 and parameters: {'n_estimators': 677, 'max_depth': 14, 'min_child_weight': 7, 'subsample': 0.6, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:55:36] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:55:38,576]\u001b[0m Trial 14 finished with value: 0.8503649635036497 and parameters: {'n_estimators': 985, 'max_depth': 9, 'min_child_weight': 14, 'subsample': 0.7, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:55:38] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:55:40,311]\u001b[0m Trial 15 finished with value: 0.8467153284671532 and parameters: {'n_estimators': 635, 'max_depth': 16, 'min_child_weight': 8, 'subsample': 0.7, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:55:40] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:55:42,553]\u001b[0m Trial 16 finished with value: 0.8503649635036497 and parameters: {'n_estimators': 833, 'max_depth': 20, 'min_child_weight': 6, 'subsample': 0.6, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:55:42] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:55:44,448]\u001b[0m Trial 17 finished with value: 0.8540145985401459 and parameters: {'n_estimators': 854, 'max_depth': 9, 'min_child_weight': 13, 'subsample': 0.7, 'colsample_bytree': 0.6}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:55:44] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:55:46,676]\u001b[0m Trial 18 finished with value: 0.8576642335766423 and parameters: {'n_estimators': 921, 'max_depth': 13, 'min_child_weight': 10, 'subsample': 0.6, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:55:46] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:55:48,405]\u001b[0m Trial 19 finished with value: 0.8503649635036497 and parameters: {'n_estimators': 746, 'max_depth': 16, 'min_child_weight': 10, 'subsample': 0.5, 'colsample_bytree': 0.7}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:55:48] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:55:50,097]\u001b[0m Trial 20 finished with value: 0.8613138686131386 and parameters: {'n_estimators': 570, 'max_depth': 9, 'min_child_weight': 5, 'subsample': 0.6, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:55:50] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:55:52,345]\u001b[0m Trial 21 finished with value: 0.8394160583941606 and parameters: {'n_estimators': 973, 'max_depth': 14, 'min_child_weight': 12, 'subsample': 0.5, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:55:52] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:55:54,590]\u001b[0m Trial 22 finished with value: 0.8357664233576643 and parameters: {'n_estimators': 1000, 'max_depth': 18, 'min_child_weight': 14, 'subsample': 0.5, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:55:54] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:55:56,599]\u001b[0m Trial 23 finished with value: 0.8357664233576643 and parameters: {'n_estimators': 889, 'max_depth': 18, 'min_child_weight': 15, 'subsample': 0.6, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:55:56] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:55:58,480]\u001b[0m Trial 24 finished with value: 0.8686131386861314 and parameters: {'n_estimators': 746, 'max_depth': 18, 'min_child_weight': 9, 'subsample': 0.5, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:55:58] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:56:00,421]\u001b[0m Trial 25 finished with value: 0.8576642335766423 and parameters: {'n_estimators': 802, 'max_depth': 16, 'min_child_weight': 14, 'subsample': 0.7, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:56:00] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:56:02,402]\u001b[0m Trial 26 finished with value: 0.8321167883211679 and parameters: {'n_estimators': 899, 'max_depth': 17, 'min_child_weight': 16, 'subsample': 0.6, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:56:02] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:56:04,430]\u001b[0m Trial 27 finished with value: 0.8394160583941606 and parameters: {'n_estimators': 899, 'max_depth': 12, 'min_child_weight': 17, 'subsample': 0.6, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:56:04] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:56:06,193]\u001b[0m Trial 28 finished with value: 0.8394160583941606 and parameters: {'n_estimators': 784, 'max_depth': 15, 'min_child_weight': 20, 'subsample': 0.7, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:56:06] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:56:08,581]\u001b[0m Trial 29 finished with value: 0.8503649635036497 and parameters: {'n_estimators': 927, 'max_depth': 14, 'min_child_weight': 9, 'subsample': 0.6, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:56:08] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:56:10,102]\u001b[0m Trial 30 finished with value: 0.8467153284671532 and parameters: {'n_estimators': 610, 'max_depth': 11, 'min_child_weight': 12, 'subsample': 0.7, 'colsample_bytree': 0.7}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:56:10] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:56:12,133]\u001b[0m Trial 31 finished with value: 0.8394160583941606 and parameters: {'n_estimators': 902, 'max_depth': 18, 'min_child_weight': 15, 'subsample': 0.6, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:56:12] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:56:14,221]\u001b[0m Trial 32 finished with value: 0.8467153284671532 and parameters: {'n_estimators': 892, 'max_depth': 19, 'min_child_weight': 16, 'subsample': 0.6, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:56:14] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:56:16,521]\u001b[0m Trial 33 finished with value: 0.8576642335766423 and parameters: {'n_estimators': 965, 'max_depth': 17, 'min_child_weight': 11, 'subsample': 0.6, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:56:16] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:56:17,958]\u001b[0m Trial 34 finished with value: 0.8613138686131386 and parameters: {'n_estimators': 702, 'max_depth': 15, 'min_child_weight': 19, 'subsample': 0.6, 'colsample_bytree': 0.6}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:56:18] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:56:19,779]\u001b[0m Trial 35 finished with value: 0.8503649635036497 and parameters: {'n_estimators': 810, 'max_depth': 17, 'min_child_weight': 13, 'subsample': 0.5, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:56:19] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:56:21,894]\u001b[0m Trial 36 finished with value: 0.8357664233576643 and parameters: {'n_estimators': 877, 'max_depth': 13, 'min_child_weight': 17, 'subsample': 0.7, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:56:21] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:56:22,742]\u001b[0m Trial 37 finished with value: 0.8795620437956204 and parameters: {'n_estimators': 299, 'max_depth': 13, 'min_child_weight': 18, 'subsample': 0.8, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:56:22] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:56:24,780]\u001b[0m Trial 38 finished with value: 0.8394160583941606 and parameters: {'n_estimators': 940, 'max_depth': 19, 'min_child_weight': 15, 'subsample': 0.6, 'colsample_bytree': 0.7}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:56:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:56:26,585]\u001b[0m Trial 39 finished with value: 0.864963503649635 and parameters: {'n_estimators': 522, 'max_depth': 12, 'min_child_weight': 4, 'subsample': 0.8, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "\u001b[32m[I 2022-07-30 19:56:26,731]\u001b[0m Trial 40 finished with value: 0.8759124087591241 and parameters: {'n_estimators': 30, 'max_depth': 10, 'min_child_weight': 17, 'subsample': 0.7, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:56:26] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[19:56:26] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:56:28,774]\u001b[0m Trial 41 finished with value: 0.8394160583941606 and parameters: {'n_estimators': 879, 'max_depth': 17, 'min_child_weight': 16, 'subsample': 0.6, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:56:28] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:56:30,691]\u001b[0m Trial 42 finished with value: 0.843065693430657 and parameters: {'n_estimators': 849, 'max_depth': 15, 'min_child_weight': 19, 'subsample': 0.7, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:56:30] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:56:33,442]\u001b[0m Trial 43 finished with value: 0.8576642335766423 and parameters: {'n_estimators': 1000, 'max_depth': 13, 'min_child_weight': 12, 'subsample': 0.9, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:56:33] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:56:35,492]\u001b[0m Trial 44 finished with value: 0.8394160583941606 and parameters: {'n_estimators': 946, 'max_depth': 15, 'min_child_weight': 15, 'subsample': 0.6, 'colsample_bytree': 0.7}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:56:35] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:56:37,741]\u001b[0m Trial 45 finished with value: 0.8321167883211679 and parameters: {'n_estimators': 997, 'max_depth': 4, 'min_child_weight': 13, 'subsample': 0.5, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:56:37] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:56:39,342]\u001b[0m Trial 46 finished with value: 0.8686131386861314 and parameters: {'n_estimators': 784, 'max_depth': 2, 'min_child_weight': 11, 'subsample': 0.5, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:56:39] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:56:39,973]\u001b[0m Trial 47 finished with value: 0.8686131386861314 and parameters: {'n_estimators': 233, 'max_depth': 7, 'min_child_weight': 13, 'subsample': 0.5, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:56:40] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:56:41,013]\u001b[0m Trial 48 finished with value: 0.8540145985401459 and parameters: {'n_estimators': 446, 'max_depth': 4, 'min_child_weight': 9, 'subsample': 0.5, 'colsample_bytree': 0.6}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:56:41] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:56:43,258]\u001b[0m Trial 49 finished with value: 0.8357664233576643 and parameters: {'n_estimators': 1000, 'max_depth': 19, 'min_child_weight': 14, 'subsample': 0.5, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:56:43] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:56:45,623]\u001b[0m Trial 50 finished with value: 0.8540145985401459 and parameters: {'n_estimators': 967, 'max_depth': 20, 'min_child_weight': 8, 'subsample': 0.5, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:56:45] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:56:47,779]\u001b[0m Trial 51 finished with value: 0.8467153284671532 and parameters: {'n_estimators': 935, 'max_depth': 19, 'min_child_weight': 13, 'subsample': 0.5, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:56:47] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:56:50,046]\u001b[0m Trial 52 finished with value: 0.8321167883211679 and parameters: {'n_estimators': 997, 'max_depth': 17, 'min_child_weight': 14, 'subsample': 0.6, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:56:50] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:56:52,362]\u001b[0m Trial 53 finished with value: 0.8467153284671532 and parameters: {'n_estimators': 995, 'max_depth': 17, 'min_child_weight': 11, 'subsample': 0.5, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:56:52] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:56:54,684]\u001b[0m Trial 54 finished with value: 0.8467153284671532 and parameters: {'n_estimators': 951, 'max_depth': 4, 'min_child_weight': 10, 'subsample': 0.6, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:56:54] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:56:56,604]\u001b[0m Trial 55 finished with value: 0.8394160583941606 and parameters: {'n_estimators': 852, 'max_depth': 7, 'min_child_weight': 12, 'subsample': 0.5, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:56:56] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:56:58,188]\u001b[0m Trial 56 finished with value: 0.8576642335766423 and parameters: {'n_estimators': 929, 'max_depth': 1, 'min_child_weight': 14, 'subsample': 0.6, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:56:58] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:57:00,325]\u001b[0m Trial 57 finished with value: 0.843065693430657 and parameters: {'n_estimators': 969, 'max_depth': 19, 'min_child_weight': 7, 'subsample': 0.6, 'colsample_bytree': 0.5}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:57:00] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:57:02,437]\u001b[0m Trial 58 finished with value: 0.8503649635036497 and parameters: {'n_estimators': 876, 'max_depth': 13, 'min_child_weight': 17, 'subsample': 0.8, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:57:02] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:57:04,206]\u001b[0m Trial 59 finished with value: 0.8613138686131386 and parameters: {'n_estimators': 815, 'max_depth': 16, 'min_child_weight': 16, 'subsample': 0.6, 'colsample_bytree': 0.7}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:57:04] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:57:06,342]\u001b[0m Trial 60 finished with value: 0.843065693430657 and parameters: {'n_estimators': 910, 'max_depth': 18, 'min_child_weight': 13, 'subsample': 0.6, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:57:06] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:57:08,458]\u001b[0m Trial 61 finished with value: 0.843065693430657 and parameters: {'n_estimators': 998, 'max_depth': 17, 'min_child_weight': 15, 'subsample': 0.5, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:57:08] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:57:10,631]\u001b[0m Trial 62 finished with value: 0.8321167883211679 and parameters: {'n_estimators': 958, 'max_depth': 20, 'min_child_weight': 14, 'subsample': 0.6, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:57:10] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:57:12,687]\u001b[0m Trial 63 finished with value: 0.8394160583941606 and parameters: {'n_estimators': 920, 'max_depth': 20, 'min_child_weight': 15, 'subsample': 0.6, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:57:12] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:57:14,784]\u001b[0m Trial 64 finished with value: 0.843065693430657 and parameters: {'n_estimators': 874, 'max_depth': 14, 'min_child_weight': 17, 'subsample': 0.7, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:57:14] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:57:17,051]\u001b[0m Trial 65 finished with value: 0.8503649635036497 and parameters: {'n_estimators': 957, 'max_depth': 14, 'min_child_weight': 18, 'subsample': 0.7, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:57:17] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:57:18,966]\u001b[0m Trial 66 finished with value: 0.8467153284671532 and parameters: {'n_estimators': 772, 'max_depth': 16, 'min_child_weight': 10, 'subsample': 0.6, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:57:19] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:57:21,169]\u001b[0m Trial 67 finished with value: 0.8394160583941606 and parameters: {'n_estimators': 970, 'max_depth': 20, 'min_child_weight': 14, 'subsample': 0.5, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:57:21] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:57:22,825]\u001b[0m Trial 68 finished with value: 0.8576642335766423 and parameters: {'n_estimators': 703, 'max_depth': 18, 'min_child_weight': 12, 'subsample': 0.6, 'colsample_bytree': 0.7}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:57:22] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:57:25,091]\u001b[0m Trial 69 finished with value: 0.8467153284671532 and parameters: {'n_estimators': 915, 'max_depth': 18, 'min_child_weight': 11, 'subsample': 0.6, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:57:25] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:57:26,946]\u001b[0m Trial 70 finished with value: 0.8503649635036497 and parameters: {'n_estimators': 836, 'max_depth': 16, 'min_child_weight': 14, 'subsample': 0.5, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:57:26] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:57:28,947]\u001b[0m Trial 71 finished with value: 0.8321167883211679 and parameters: {'n_estimators': 899, 'max_depth': 17, 'min_child_weight': 16, 'subsample': 0.6, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:57:29] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:57:31,151]\u001b[0m Trial 72 finished with value: 0.8357664233576643 and parameters: {'n_estimators': 999, 'max_depth': 19, 'min_child_weight': 16, 'subsample': 0.6, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:57:31] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:57:33,187]\u001b[0m Trial 73 finished with value: 0.8321167883211679 and parameters: {'n_estimators': 871, 'max_depth': 15, 'min_child_weight': 17, 'subsample': 0.7, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:57:33] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:57:35,116]\u001b[0m Trial 74 finished with value: 0.843065693430657 and parameters: {'n_estimators': 899, 'max_depth': 15, 'min_child_weight': 19, 'subsample': 0.6, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:57:35] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:57:37,279]\u001b[0m Trial 75 finished with value: 0.864963503649635 and parameters: {'n_estimators': 828, 'max_depth': 15, 'min_child_weight': 9, 'subsample': 0.7, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:57:37] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:57:39,258]\u001b[0m Trial 76 finished with value: 0.843065693430657 and parameters: {'n_estimators': 944, 'max_depth': 17, 'min_child_weight': 18, 'subsample': 0.6, 'colsample_bytree': 0.7}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:57:39] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:57:41,257]\u001b[0m Trial 77 finished with value: 0.843065693430657 and parameters: {'n_estimators': 856, 'max_depth': 16, 'min_child_weight': 16, 'subsample': 0.7, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:57:41] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:57:43,397]\u001b[0m Trial 78 finished with value: 0.8394160583941606 and parameters: {'n_estimators': 961, 'max_depth': 10, 'min_child_weight': 16, 'subsample': 0.6, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:57:43] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:57:45,607]\u001b[0m Trial 79 finished with value: 0.8503649635036497 and parameters: {'n_estimators': 915, 'max_depth': 14, 'min_child_weight': 13, 'subsample': 0.8, 'colsample_bytree': 0.7}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:57:45] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:57:47,305]\u001b[0m Trial 80 finished with value: 0.8467153284671532 and parameters: {'n_estimators': 863, 'max_depth': 2, 'min_child_weight': 15, 'subsample': 0.6, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:57:47] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:57:49,607]\u001b[0m Trial 81 finished with value: 0.8357664233576643 and parameters: {'n_estimators': 977, 'max_depth': 18, 'min_child_weight': 14, 'subsample': 0.6, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:57:49] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:57:51,714]\u001b[0m Trial 82 finished with value: 0.8467153284671532 and parameters: {'n_estimators': 879, 'max_depth': 12, 'min_child_weight': 18, 'subsample': 0.7, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:57:51] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:57:53,857]\u001b[0m Trial 83 finished with value: 0.8394160583941606 and parameters: {'n_estimators': 894, 'max_depth': 13, 'min_child_weight': 17, 'subsample': 0.7, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:57:53] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:57:55,953]\u001b[0m Trial 84 finished with value: 0.8394160583941606 and parameters: {'n_estimators': 934, 'max_depth': 12, 'min_child_weight': 20, 'subsample': 0.7, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:57:56] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:57:56,453]\u001b[0m Trial 85 finished with value: 0.8795620437956204 and parameters: {'n_estimators': 152, 'max_depth': 17, 'min_child_weight': 15, 'subsample': 0.6, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:57:56] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:57:58,632]\u001b[0m Trial 86 finished with value: 0.8394160583941606 and parameters: {'n_estimators': 981, 'max_depth': 19, 'min_child_weight': 16, 'subsample': 0.6, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:57:58] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:58:00,838]\u001b[0m Trial 87 finished with value: 0.8467153284671532 and parameters: {'n_estimators': 951, 'max_depth': 8, 'min_child_weight': 12, 'subsample': 0.5, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:58:00] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:58:02,879]\u001b[0m Trial 88 finished with value: 0.8503649635036497 and parameters: {'n_estimators': 802, 'max_depth': 16, 'min_child_weight': 8, 'subsample': 0.6, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:58:02] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:58:05,227]\u001b[0m Trial 89 finished with value: 0.8467153284671532 and parameters: {'n_estimators': 984, 'max_depth': 20, 'min_child_weight': 10, 'subsample': 0.6, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:58:05] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:58:06,704]\u001b[0m Trial 90 finished with value: 0.8576642335766423 and parameters: {'n_estimators': 637, 'max_depth': 15, 'min_child_weight': 16, 'subsample': 0.6, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:58:06] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:58:08,969]\u001b[0m Trial 91 finished with value: 0.843065693430657 and parameters: {'n_estimators': 931, 'max_depth': 18, 'min_child_weight': 15, 'subsample': 0.6, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:58:09] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:58:11,048]\u001b[0m Trial 92 finished with value: 0.843065693430657 and parameters: {'n_estimators': 904, 'max_depth': 17, 'min_child_weight': 14, 'subsample': 0.5, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:58:11] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:58:13,326]\u001b[0m Trial 93 finished with value: 0.8321167883211679 and parameters: {'n_estimators': 1000, 'max_depth': 14, 'min_child_weight': 17, 'subsample': 0.7, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:58:13] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:58:15,519]\u001b[0m Trial 94 finished with value: 0.843065693430657 and parameters: {'n_estimators': 953, 'max_depth': 14, 'min_child_weight': 17, 'subsample': 0.7, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:58:15] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:58:17,482]\u001b[0m Trial 95 finished with value: 0.8467153284671532 and parameters: {'n_estimators': 980, 'max_depth': 16, 'min_child_weight': 13, 'subsample': 0.5, 'colsample_bytree': 0.6}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:58:17] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:58:19,844]\u001b[0m Trial 96 finished with value: 0.843065693430657 and parameters: {'n_estimators': 1000, 'max_depth': 15, 'min_child_weight': 17, 'subsample': 0.8, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:58:19] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:58:21,921]\u001b[0m Trial 97 finished with value: 0.8394160583941606 and parameters: {'n_estimators': 937, 'max_depth': 19, 'min_child_weight': 16, 'subsample': 0.6, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:58:21] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:58:24,008]\u001b[0m Trial 98 finished with value: 0.8321167883211679 and parameters: {'n_estimators': 976, 'max_depth': 20, 'min_child_weight': 19, 'subsample': 0.6, 'colsample_bytree': 0.8}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n",
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:58:24] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-07-30 19:58:26,086]\u001b[0m Trial 99 finished with value: 0.8467153284671532 and parameters: {'n_estimators': 965, 'max_depth': 11, 'min_child_weight': 19, 'subsample': 0.7, 'colsample_bytree': 0.7}. Best is trial 10 with value: 0.8284671532846716.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study()\n",
    "study.optimize(functools.partial(opt, features_train, target_train, features_test, target_test), n_trials=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de97698d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 958,\n",
       " 'max_depth': 14,\n",
       " 'min_child_weight': 10,\n",
       " 'subsample': 0.6,\n",
       " 'colsample_bytree': 0.9}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ecf1217",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19:58:26] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "F1: 0.8371961303699157\n",
      "Accuracy: 0.8467153284671532\n"
     ]
    }
   ],
   "source": [
    "model_xg = xgb.XGBClassifier(**study.best_params)\n",
    "model_xg.fit(features_train, target_train)\n",
    "p = model_xg.predict(features_test)\n",
    "print('F1:', f1_score(target_test, p, average='weighted'))\n",
    "print('Accuracy:', accuracy_score(target_test, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a512b518",
   "metadata": {},
   "source": [
    "## Bert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb69367",
   "metadata": {},
   "source": [
    "Попробуем добиться лучшего результат используя BERT для векторизации данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5798fa4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>remote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Желание работать на всесезонной базе отдыха кл...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>График работы: 5/2, возможна удаленная работа ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.Ежедневная проверка классных и домашних рабо...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Работа РЯДОМ С ДОМОМ</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Удаленная работа</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  remote\n",
       "0  Желание работать на всесезонной базе отдыха кл...       0\n",
       "1  График работы: 5/2, возможна удаленная работа ...       1\n",
       "2  6.Ежедневная проверка классных и домашних рабо...       0\n",
       "3                               Работа РЯДОМ С ДОМОМ      -1\n",
       "4                                   Удаленная работа       1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('C:/Users/User/Desktop/123/test.csv')\n",
    "data.columns=['id', 'found_in', 'text', 'remote']\n",
    "data = data[['text', 'remote']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a3a59f6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>remote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Желание работать на всесезонной базе отдыха кл...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>График работы: 5/2, возможна удаленная работа ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.Ежедневная проверка классных и домашних рабо...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Работа РЯДОМ С ДОМОМ</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Удаленная работа</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1295</th>\n",
       "      <td>Работа РЯДОМ С ДОМОМ</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1296</th>\n",
       "      <td>Возможна частично удаленная работа</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1297</th>\n",
       "      <td>удаленная работа из любой точки мира, но в мос...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1298</th>\n",
       "      <td>Условия:  Удаленная работа</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>Пермь с удаленной работой</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1300 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  remote\n",
       "0     Желание работать на всесезонной базе отдыха кл...       0\n",
       "1     График работы: 5/2, возможна удаленная работа ...       1\n",
       "2     6.Ежедневная проверка классных и домашних рабо...       0\n",
       "3                                  Работа РЯДОМ С ДОМОМ      -1\n",
       "4                                      Удаленная работа       1\n",
       "...                                                 ...     ...\n",
       "1295                               Работа РЯДОМ С ДОМОМ      -1\n",
       "1296                 Возможна частично удаленная работа       1\n",
       "1297  удаленная работа из любой точки мира, но в мос...       1\n",
       "1298                         Условия:  Удаленная работа       1\n",
       "1299                          Пермь с удаленной работой       1\n",
       "\n",
       "[1300 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new = data[:1300]\n",
    "data_test = data[1300:]\n",
    "data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "139d2895",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny2 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"cointegrated/rubert-tiny2\")\n",
    "model = AutoModel.from_pretrained(\"cointegrated/rubert-tiny2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "dbb6188b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = data_new['text'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8f7c6135",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny2 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7c4d030acfc4399b00961c15d900ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.8990041758539927\n",
      "Accuracy: 0.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\miniconda3\\envs\\praktikum_new\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(\"cointegrated/rubert-tiny2\")\n",
    "batch_size = 100\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "    batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)])\n",
    "    attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "    with torch.no_grad(): batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "    embeddings.append(batch_embeddings[0][:,0,:].numpy())\n",
    "features = np.concatenate(embeddings)\n",
    "target = data_new['remote']\n",
    "train_features, test_features, train_target, test_target = train_test_split(features, target, test_size=0.2)\n",
    "model_1 = LogisticRegression()\n",
    "model_1.fit(train_features, train_target)\n",
    "p = model_1.predict(test_features)\n",
    "print('F1:', f1_score(test_target, p, average='weighted'))\n",
    "print('Accuracy:', accuracy_score(test_target, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1c0494",
   "metadata": {},
   "source": [
    "Проверим на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "66339edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cointegrated/rubert-tiny2 were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ebec8f027c1422bae77ed1e308fd347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/68 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.8154761904761905\n",
      "Accuracy: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "tokenized = data_test['text'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "model = AutoModel.from_pretrained(\"cointegrated/rubert-tiny2\")\n",
    "batch_size = 1\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "    batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)])\n",
    "    attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "    with torch.no_grad(): batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "    embeddings.append(batch_embeddings[0][:,0,:].numpy())\n",
    "features_test = np.concatenate(embeddings)\n",
    "target_test = data_test['remote']\n",
    "train_features, test_features, train_target, test_target = train_test_split(features_test, target_test, test_size=0.2)\n",
    "p = model_1.predict(test_features)\n",
    "print('F1:', f1_score(test_target, p, average='weighted'))\n",
    "print('Accuracy:', accuracy_score(test_target, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e38dba",
   "metadata": {},
   "source": [
    "## Вывод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f7a00c",
   "metadata": {},
   "source": [
    "Изначальный текст был лемматизирован и избавлен от лишних символов. Была проведена векторизация текста для обучения моделей.  Лучший результат получился у логистической регрессии, при использовании Bert для векторизации текста.\n",
    "\n",
    "Получилось достичь точности:\n",
    "- F1=0.899\n",
    "- Accuracy=0.9\n",
    "\n",
    "На тестовой выборке результат получился:\n",
    "- F1=0.815\n",
    "- Accuracy=0.857\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66067ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
